{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import libs.config\n",
    "import libs.files as fh\n",
    "import libs.pipeline as pipe\n",
    "import libs.parse as p\n",
    "import libs.twokenize as ark\n",
    "import libs.resources as r\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the SemEval 2015, the task 10 part b is related to the Tweet sentiment analysis. The train and test dataset are the same used in 2013 and 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the train file\n",
    "# tw_downloaded = \"../1-Input/2014/SemEval2014-task9-test-B-gold.txt.error\"\n",
    "# original_file = \"../1-Input/2014/SemEval2014-task9-test-B-gold-NEED-TWEET-DOWNLOAD.txt\"\n",
    "final_file = \"../1-Input/2015/SemEval2015_test.csv\"\n",
    "gold_file = \"../1-Input/2015/SemEval2015-task10-test-B-gold.txt\"\n",
    "sarcasm_file = \"../1-Input/2015/SemEval2014-task9-test-B-sarcasm.txt\"\n",
    "\n",
    "# the task in SEMEVAL\n",
    "file_type = 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2389 rows from ../1-Input/2015/SemEval2015_test.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1394"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the file\n",
    "test_feat, gold, test_tweets = pipe.create_features(final_file, file_type, '')\n",
    "len(test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 9683 rows from ../1-Input/trainingData-B.tsv\n",
      "Read 1653 rows from ../1-Input/devData-B.tsv\n"
     ]
    }
   ],
   "source": [
    "# read the information\n",
    "OUTPUT_DIR = '../3-Output/'\n",
    "MODEL_OUT_DIR = '../6-Models'\n",
    "CREATE_TOKENS_FILES = True\n",
    "PROCESS_DIR = '../2-Processed'\n",
    "rnd = 9000\n",
    "\n",
    "# read the config file\n",
    "cfg = fh.read_config_file(\"all.yaml\")\n",
    "\n",
    "# read the train file\n",
    "file_name = \"../1-Input/trainingData-B.tsv\"\n",
    "file_type = 'B'\n",
    "train, labels, train_tweets = pipe.create_features(file_name, file_type, cfg)\n",
    "\n",
    "# read the dev file\n",
    "file_name = \"../1-Input/devData-B.tsv\"\n",
    "file_type = 'B'\n",
    "dev, dev_labels, dev_tweets = pipe.create_features(file_name, file_type, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9576, 19847)\n",
      "dev shape: (1394, 19847)\n",
      "Final shape (9576, 993) (1394, 993)\n"
     ]
    }
   ],
   "source": [
    "# random seed for all the operations\n",
    "rnd_seed = 9000\n",
    "\n",
    "# join datasets\n",
    "train_final = train_tweets[:]\n",
    "train_final.extend(dev_tweets)\n",
    "\n",
    "# convert the list into and array that can be indexed\n",
    "train_labels = np.concatenate((np.array(labels),np.array(dev_labels)))\n",
    "gold = np.array(gold)\n",
    "\n",
    "# create the cleaned the tweets\n",
    "train_clean, test_clean, vect = pipe.create_count_vec(train_final, test_tweets, tokenizer=pipe.tokenize_clean_raw, stop_words=pipe.stop_words)\n",
    "train_data, test_data, _ = pipe.auto_select_features(pipe.chi2, 5, train_clean, train_labels, test_clean, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using negated tokens\n",
    "train_neg_tokens = [pipe.tokenize_negate_clean_raw(t) for t in train_final]\n",
    "test_neg_tokens = [pipe.tokenize_negate_clean_raw(t) for t in test_tweets]\n",
    "\n",
    "# not using negated tokens\n",
    "train_tokens = [pipe.tokenize_clean_raw(t) for t in train_final]\n",
    "test_tokens = [pipe.tokenize_clean_raw(t) for t in test_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_gene(ind):\n",
    "    \"\"\"\n",
    "    Decode a gene to a information that can be processed.\n",
    "    \"\"\"\n",
    "    return [r.lexs[idx] for idx, present in enumerate(ind) if present]\n",
    "\n",
    "def select_features(lex, train_feat, labels, test_feat):\n",
    "    \"\"\"\n",
    "    Select the most important features according to a given criteria.\n",
    "    \"\"\"\n",
    "    tmp_train_feat, tmp_test_feat, _, _ = pipe.create_lex_vec(train_feat, test_feat)\n",
    "    tmp_train_feat, tmp_test_feat, selector = pipe.auto_select_features(pipe.mutual_info_classif, lex.selection_percent, \n",
    "                                                                       tmp_train_feat, labels, \n",
    "                                                                       tmp_test_feat, None)\n",
    "    return tmp_train_feat, tmp_test_feat\n",
    "\n",
    "def create_ind_features(ind, base_train, base_test, train_tokens, test_tokens):\n",
    "    \"\"\"\n",
    "    Given an individual, create the features according to its genes\n",
    "    Params:\n",
    "        ind: individual generated in the genetic algorithm\n",
    "    Returns:\n",
    "        train and test data as a scipy sparse matrix\n",
    "    \"\"\"\n",
    "     # remove the last locus as it refers to the LIWC\n",
    "    LIWC_gene = ind[-1]\n",
    "    tmp_ind = ind[:-1]\n",
    "    \n",
    "    # load the lexicons according to the gens\n",
    "    ind_lexs = decode_gene(tmp_ind)\n",
    "    \n",
    "    # for each of the lexicons, merge them\n",
    "    final_train = base_train.copy()\n",
    "    final_test = base_test.copy()\n",
    "\n",
    "    for lex in ind_lexs:\n",
    "#         try:\n",
    "        print('Joining the lex {}'.format(lex.prefix))\n",
    "        # create the features from the datasets tokens\n",
    "        if False:\n",
    "            train_feat = lex.process_lex(train_neg_tokens, use_best_features=True)\n",
    "            test_feat = lex.process_lex(test_neg_tokens, use_best_features=True)\n",
    "        else:\n",
    "            train_feat = lex.process_lex(train_tokens, use_best_features=True)\n",
    "            test_feat = lex.process_lex(test_tokens, use_best_features=True)\n",
    "\n",
    "#         print len(train_feat), len(test_feat)\n",
    "#             print  test_feat[:3]\n",
    "\n",
    "        # select the top percent features if this is the case. Set the flag to create vector at save if selection occurs\n",
    "        if lex.selection_percent:\n",
    "            train_feat, test_feat = select_features(lex, train_feat, train_labels, test_feat)\n",
    "        else:\n",
    "            train_feat, test_feat, _,_ = pipe.create_lex_vec(train_feat, test_feat)\n",
    "\n",
    "#         print train_data.shape, test_data.shape\n",
    "        final_train, final_test = pipe.join_lex_features(final_train, train_feat, \n",
    "                                                         final_test, test_feat, \n",
    "                                                         verbose=True, create_vec=False)\n",
    "#         except:\n",
    "#             u.print_exception()\n",
    "#             print 'error loading ind', ind\n",
    "#             print lex\n",
    "\n",
    "        # check if should add LIWC\n",
    "    if LIWC_gene:\n",
    "        final_train, final_test = pipe.join_lex_features(final_train, full_train_liwc, \n",
    "                                                        final_test, test_liwc, \n",
    "                                                        verbose=False, create_vec=True)   \n",
    "        print final_train.shape, final_test.shape\n",
    "    return final_train, final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining the lex BING\n",
      "train data, lex and final shape:  (9576, 993) (9576, 7) (9576, 1000)\n",
      "test data, lex and final shape:  (1394, 993) (1394, 7) (1394, 1000)\n",
      "Joining the lex SWN\n",
      "train data, lex and final shape:  (9576, 1000) (9576, 8) (9576, 1008)\n",
      "test data, lex and final shape:  (1394, 1000) (1394, 8) (1394, 1008)\n",
      "Joining the lex MSOL\n",
      "Final shape (9576, 413) (1394, 413)\n",
      "train data, lex and final shape:  (9576, 1008) (9576, 413) (9576, 1421)\n",
      "test data, lex and final shape:  (1394, 1008) (1394, 413) (1394, 1421)\n",
      "Joining the lex NRCHASH\n",
      "train data, lex and final shape:  (9576, 1421) (9576, 7) (9576, 1428)\n",
      "test data, lex and final shape:  (1394, 1421) (1394, 7) (1394, 1428)\n",
      "Joining the lex TSLEX\n",
      "train data, lex and final shape:  (9576, 1428) (9576, 7) (9576, 1435)\n",
      "test data, lex and final shape:  (1394, 1428) (1394, 7) (1394, 1435)\n",
      "Joining the lex WNA\n",
      "Final shape (9576, 111) (1394, 111)\n",
      "train data, lex and final shape:  (9576, 1435) (9576, 111) (9576, 1546)\n",
      "test data, lex and final shape:  (1394, 1435) (1394, 111) (1394, 1546)\n",
      "Joining the lex DAL\n",
      "train data, lex and final shape:  (9576, 1546) (9576, 5) (9576, 1551)\n",
      "test data, lex and final shape:  (1394, 1546) (1394, 5) (1394, 1551)\n",
      "Joining the lex EMOLX\n",
      "train data, lex and final shape:  (9576, 1551) (9576, 50) (9576, 1601)\n",
      "test data, lex and final shape:  (1394, 1551) (1394, 50) (1394, 1601)\n"
     ]
    }
   ],
   "source": [
    "# read best gene\n",
    "df = pd.read_csv('../3-Output/population.csv', header=None, sep=';')\n",
    "df.columns = ['Gene', 'Stats']\n",
    "\n",
    "# create the best gene combination\n",
    "best_individual = eval(df.iloc[0]['Gene'])\n",
    "X_train, X_test = create_ind_features(best_individual, \n",
    "                                      train_data, test_data, \n",
    "                                      train_neg_tokens, test_neg_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_val_scores = pipe.run_multiple_class(X_train, train_labels, X_test, gold, \n",
    "                                           rnd_seed=rnd_seed, use_best_params=True,\n",
    "                                           test_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style  type=\"text/css\" >\n",
       "        \n",
       "        \n",
       "            #T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row0_col0 {\n",
       "            \n",
       "                font-weight:  bold;\n",
       "            \n",
       "                background-color:  rgb(200,200,200);\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row0_col1 {\n",
       "            \n",
       "                font-weight:  bold;\n",
       "            \n",
       "                background-color:  rgb(200,200,200);\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row0_col2 {\n",
       "            \n",
       "                font-weight:  bold;\n",
       "            \n",
       "                background-color:  rgb(200,200,200);\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row0_col3 {\n",
       "            \n",
       "                : ;\n",
       "            \n",
       "                background-color:  rgb(247,247,247);\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row0_col4 {\n",
       "            \n",
       "                font-weight:  bold;\n",
       "            \n",
       "                background-color:  rgb(200,200,200);\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row1_col0 {\n",
       "            \n",
       "                : ;\n",
       "            \n",
       "                background-color:  rgb(247,247,247);\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row1_col1 {\n",
       "            \n",
       "                : ;\n",
       "            \n",
       "                background-color:  rgb(247,247,247);\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row1_col2 {\n",
       "            \n",
       "                : ;\n",
       "            \n",
       "                background-color:  rgb(247,247,247);\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row1_col3 {\n",
       "            \n",
       "                : ;\n",
       "            \n",
       "                background-color:  rgb(220,220,220);\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row1_col4 {\n",
       "            \n",
       "                : ;\n",
       "            \n",
       "                background-color:  rgb(247,247,247);\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row2_col0 {\n",
       "            \n",
       "                : ;\n",
       "            \n",
       "                background-color:  rgb(220,220,220);\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row2_col1 {\n",
       "            \n",
       "                : ;\n",
       "            \n",
       "                background-color:  rgb(220,220,220);\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row2_col2 {\n",
       "            \n",
       "                : ;\n",
       "            \n",
       "                background-color:  rgb(220,220,220);\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row2_col3 {\n",
       "            \n",
       "                font-weight:  bold;\n",
       "            \n",
       "                background-color:  rgb(200,200,200);\n",
       "            \n",
       "            }\n",
       "        \n",
       "            #T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row2_col4 {\n",
       "            \n",
       "                : ;\n",
       "            \n",
       "                background-color:  rgb(220,220,220);\n",
       "            \n",
       "            }\n",
       "        \n",
       "        </style>\n",
       "\n",
       "        <table id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7\" None>\n",
       "        \n",
       "\n",
       "        <thead>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th class=\"blank\">\n",
       "                \n",
       "                <th class=\"col_heading level0 col0\">train score\n",
       "                \n",
       "                <th class=\"col_heading level0 col1\">test score\n",
       "                \n",
       "                <th class=\"col_heading level0 col2\">f1_test_neg\n",
       "                \n",
       "                <th class=\"col_heading level0 col3\">f1_test_neu\n",
       "                \n",
       "                <th class=\"col_heading level0 col4\">f1_test_pos\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </thead>\n",
       "        <tbody>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7\" class=\"row_heading level4 row0\">\n",
       "                    LogisticRegression\n",
       "                \n",
       "                <td id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row0_col0\" class=\"data row0 col0\">\n",
       "                    0.677 +- 0.024\n",
       "                \n",
       "                <td id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row0_col1\" class=\"data row0 col1\">\n",
       "                    0.591 +- 0.005\n",
       "                \n",
       "                <td id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row0_col2\" class=\"data row0 col2\">\n",
       "                    0.529 +- 0.008\n",
       "                \n",
       "                <td id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row0_col3\" class=\"data row0 col3\">\n",
       "                    0.684 +- 0.003\n",
       "                \n",
       "                <td id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row0_col4\" class=\"data row0 col4\">\n",
       "                    0.654 +- 0.006\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7\" class=\"row_heading level4 row1\">\n",
       "                    SGDClassifier\n",
       "                \n",
       "                <td id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row1_col0\" class=\"data row1 col0\">\n",
       "                    0.673 +- 0.027\n",
       "                \n",
       "                <td id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row1_col1\" class=\"data row1 col1\">\n",
       "                    0.559 +- 0.033\n",
       "                \n",
       "                <td id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row1_col2\" class=\"data row1 col2\">\n",
       "                    0.495 +- 0.033\n",
       "                \n",
       "                <td id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row1_col3\" class=\"data row1 col3\">\n",
       "                    0.693 +- 0.010\n",
       "                \n",
       "                <td id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row1_col4\" class=\"data row1 col4\">\n",
       "                    0.623 +- 0.057\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                \n",
       "                <th id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7\" class=\"row_heading level4 row2\">\n",
       "                    LinearSVC\n",
       "                \n",
       "                <td id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row2_col0\" class=\"data row2 col0\">\n",
       "                    0.676 +- 0.018\n",
       "                \n",
       "                <td id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row2_col1\" class=\"data row2 col1\">\n",
       "                    0.571 +- 0.005\n",
       "                \n",
       "                <td id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row2_col2\" class=\"data row2 col2\">\n",
       "                    0.503 +- 0.007\n",
       "                \n",
       "                <td id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row2_col3\" class=\"data row2 col3\">\n",
       "                    0.695 +- 0.005\n",
       "                \n",
       "                <td id=\"T_5d3a30e3_82f6_11e7_ac7a_9801a78ebcb7row2_col4\" class=\"data row2 col4\">\n",
       "                    0.639 +- 0.005\n",
       "                \n",
       "            </tr>\n",
       "            \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<pandas.formats.style.Styler at 0x14ac8b810>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.pprint_results(final_val_scores, test_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_scores = pipe.predict_test_multi_proc('LogisticRegression', X_train, train_labels, X_test, gold, test_name='test', rnd_seed=rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>f1_test_neg</th>\n",
       "      <th>f1_test_neu</th>\n",
       "      <th>f1_test_pos</th>\n",
       "      <th>train std</th>\n",
       "      <th>test std</th>\n",
       "      <th>f1_test_neg std</th>\n",
       "      <th>f1_test_neu std</th>\n",
       "      <th>f1_test_pos std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.75076</td>\n",
       "      <td>0.59669</td>\n",
       "      <td>0.535433</td>\n",
       "      <td>0.690513</td>\n",
       "      <td>0.657948</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.170278e-16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    train score  test score  f1_test_neg  f1_test_neu  \\\n",
       "LogisticRegression      0.75076     0.59669     0.535433     0.690513   \n",
       "\n",
       "                    f1_test_pos  train std  test std  f1_test_neg std  \\\n",
       "LogisticRegression     0.657948   0.000136       0.0              0.0   \n",
       "\n",
       "                    f1_test_neu std  f1_test_pos std  \n",
       "LogisticRegression     1.170278e-16              0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the output\n",
    "cls = pipe.LogisticRegression(**pipe.lr_params)\n",
    "cls.set_params(random_state=rnd_seed)\n",
    "cls.fit(X_train, train_labels)\n",
    "pred_test = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decode = {\n",
    "    -1: \"negative\",\n",
    "    0:\"neutral\",\n",
    "    1: \"positive\"\n",
    "}\n",
    "pred_test_labels = [ decode[val] for val in pred_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate final file for submission\n",
    "The final submission has a specific format that needs to be followed so that it can be properly evaluated. As some tweets were not available, the prediction is made as neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dictionary with all the key/answers pair as we have missing text in the output\n",
    "out_text = []\n",
    "for tf,pred in zip(test_feat, pred_test_labels):\n",
    "    out_text.append(u\"NA\\t{}\\t{}\\n\".format(tf.uid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_file = '../3-Output/prediction_2015.csv'\n",
    "with codecs.open(out_file, 'w', 'utf-8') as f:\n",
    "    f.writelines(out_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final submission scored by SemEval 2014 script was :\n",
    "\n",
    "| LiveJournal2014\t| \tSMS2013\t| \tTwitter2013\t| \tTwitter2014\t| \tTwitter2014Sarcasm\t| \n",
    "|-------------------------------|--------|-------|-------|-------|\n",
    "|71.11  | 65.89     | 58.51     | 56.21     |  42.05     |\n",
    "\n",
    "\n",
    "\n",
    "Not a very good score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sarcasm\n",
    "2015 had a small sample of tweets that were ideintified as sarcasm. Checking how was the performance on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(sarcasm_file, header=None, sep='\\t')\n",
    "sarcasm_tweets = df[0].apply(lambda x: unicode(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "decode = {\n",
    "    \"negative\":-1,\n",
    "    \"neutral\":0,\n",
    "    \"positive\":1,\n",
    "    None:None\n",
    "}\n",
    "pred_sarcasm = []\n",
    "gold_sarcasm = []\n",
    "for tf,pred in zip(test_feat, pred_test_labels):\n",
    "    if tf.sid in sarcasm_tweets:\n",
    "        pred_sarcasm.append(decode[pred])\n",
    "        gold_sarcasm.append(decode[tf.sent])\n",
    "        \n",
    "print len(pred_sarcasm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'52.22'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{0:0.2f}'.format(100.0*pipe.score_func(gold_sarcasm, pred_sarcasm))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
